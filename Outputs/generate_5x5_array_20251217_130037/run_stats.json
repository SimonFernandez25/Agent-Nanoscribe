{
  "timestamp": "2025-12-17T13:01:01.203507",
  "node_name": "final_metrics",
  "content": {
    "total_runtime_sec": 22.712,
    "input_tokens": 17452,
    "output_tokens": 831,
    "total_tokens": 18283,
    "llm_calls": 4,
    "docs_tokens_per_call": 3831,
    "note": "Input tokens include full context (system prompt + user prompt + docs) for each LLM call"
  },
  "metadata": {}
}